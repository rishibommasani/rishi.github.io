---
layout: default
title: Rishi Bommasani
---
<div class="blurb">
<h1> Rishi Bommasani</h1>
<p>Hi! I'm a third-year Stanford CS Ph.D. advised by <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a> and <a href="https://web.stanford.edu/~jurafsky/">Dan Jurafsky</a>.
<br> I helped build and organize the <a href="https://crfm.stanford.edu/">Center for Research on Foundation Models (CRFM)</a>.
<br> Affiliations: <a href="https://nlp.stanford.edu/">Stanford NLP</a>, <a href="https://ai.stanford.edu/">Stanford AI</a>, and <a href="https://hai.stanford.edu/">Stanford HAI</a>. Funding: <a href="https://www.nsfgrfp.org/resources/about_grfp">NSF GRFP</a>. </p>

<p> Prior to Stanford, I got my start in research at Cornell (BA Math & CS '16-'19, MS CS '19-'20) under the masterful guidance of <a href="http://www.cs.cornell.edu/home/cardie/">Claire Cardie</a>.
<br> I am honored to have learned from the <a href="https://news.psu.edu/story/660710/2021/06/07/college-engineering-mourns-loss-faculty-member-arzoo-katiyar">late</a> <a href="https://sites.google.com/site/arzook99/home">Professor Arzoo Katiyar</a>, who I profoundly miss. 
<br> During my time there, Cornell CS was my home: the department wrote this about my journey. <a href="https://www.cs.cornell.edu/information/news/newsitem11229/profile-cornell-cs-ba-and-ms-graduate-rishi-bommasani"> [Profile] </a> <a href="https://www.cs.cornell.edu/information/news/newsitem11227/lillian-lee-and-tacl-cs-graduate-stanford-new-platform-data-privacy"> [Profile 2] </a> </p>

<p> I research the societal impact of AI, especially <a href="https://arxiv.org/abs/2108.07258">foundation models</a>.
<ul>
<li><b>Transparency</b> (establish the basic facts). <a href="https://arxiv.org/abs/2211.09110">evaluation</a>, <a href="https://www.aclweb.org/anthology/2020.emnlp-main.649.pdf">data</a>, <a href="https://arxiv.org/abs/2212.09746">interaction</a>
<li><b>Concepts</b> (introduce important new ideas). <a href="https://arxiv.org/abs/2211.13972">homogenization</a>, <a href="https://arxiv.org/abs/2212.11672">trust</a>, <a href="https://arxiv.org/abs/2206.07682">emergence</a>, <a href="https://arxiv.org/abs/2206.03216">governance</a>
<li><b>Progress</b> (drive concrete societal change). <a href="https://arxiv.org/abs/2212.11670">power</a>, <a href="https://hai.stanford.edu/foundation-model-issue-brief-series">policy</a>, <a href="https://crfm.stanford.edu/2022/05/17/community-norms.html">norms</a>
</ul>
		
<div class="blurb">
<h1> Talks.</h1>
<ul>
<li><b>July 2023</b> Talk at United Nations Conference on Large Generative Models (Host: Philipp Hacker, Sarah Hammer) </li>
<li><b>July 2023</b> Panel on Language Models, Law, and Policy at NYU School of Law (Host: Paul Friedl, Gabriel Nicholas) </li>
<li><b>June 2023</b> Talk at <a href="https://www.nist.gov/programs-projects/ai-measurement-and-evaluation/ai-metrology-colloquia-series">NIST Measurement and Evaluation Series</a> (Host: Afzal Godil) </li>
<li><b>May 2023</b> Talk at Princeton (Host: Arvind Narayanan) </li>
<li><b>February 2023</b> Talk at <a href="https://mlcollective.org/dlct/">ML Collective</a> (Host: Rosanne Liu) </li>
<li><b>February 2023</b> Guest lecture for <a href="https://ai4comm.media.mit.edu/">MIT MAS.S68</a> (Host: Deb Roy, Shayne Longpre, Hang Jiang, Hope Schroeder) </li>
<li><b>February 2023</b> Talk at ENS Paris (Host: Emmanuel Dupoux, Tu Anh Nguyen, Mathieu Rita) </li>
<li><b>January 2023</b> Talk at Technion (Host: Yonatan Belinkov, Zachary Bamberger) </li>
<li><b>January 2023</b> Talk at Partnership on AI (Host: Madhulika Srikumar, Elissa Redmiles) </li>
<li><b>December 2022</b> Guest lecture for <a href="https://www.cs.cmu.edu/~aditirag/teaching/15-884F22.html">CMU CS 15-884</a> (Host: Aditi Raghunathan) </li>
<li><b>October 2022</b> Talk at <a href="https://sites.google.com/view/osu-cse-ai-seminar/home">OSU's CSE AI Seminar</a> (Host: Yu Su, Huan Sun, Harry Chao) </li>
<li><b>August 2022</b> Fireside chat with Percy at <a href="https://hai.stanford.edu/congressional-boot-camp-ai">Congressional Boot Camp on Artificial Intelligence</a> (Host: Stanford HAI) </li>
<li><b>October 2021</b> Talk at MIT NLP (Host: Jacob Andreas, Belinda Li) </li>
<li><b>October 2021</b> Talk at FAIR NLP (Host: Myle Ott) </li>
</ul>
	
<div class="blurb">
<h1> What have I been up to?</h1>
<ul>
<li><b>February 2023</b> As CRFM's first policy effort, I wrote a brief on transparency + evaluation for LMs with <a href="https://profiles.stanford.edu/danielzhang">Daniel Zhang</a>, <a href="https://www.linkedin.com/in/tonyhlee">Tony Lee</a>, and Percy. <a href="https://hai.stanford.edu/sites/default/files/2023-02/HAI%20Policy%20%26%20Society%20Issue%20Brief%20-%20Improving%20Transparency%20in%20AI%20Language%20Models.pdf">[Policy Brief]</a> </li>
<li><b>December 2022</b> I wrote two papers on evaluation: Evaluation for Change (E4C; position paper) and Trustworthy Social Bias Measurement (DivDist; w/ Percy). <a href="https://arxiv.org/abs/2212.11670">[E4C]</a> <a href="https://arxiv.org/abs/2212.11672">[DivDist]</a> </li>
<li><b>December 2022</b> Led by <a href="https://minalee.info/">Mina Lee</a>, we released Evaluating Human-Language Model Interaction! Mina is on the job market! <a href="https://arxiv.org/abs/2212.09746">[Paper]</a> </li>
<li><b>November 2022</b> I presented our paper at NeurIPS on systemic harms to individuals, coauthored with <a href="https://kathleenacreel.com/">Katie Creel</a>, <a href="https://ananyakumar.wordpress.com/">Ananya Kumar (on job market!)</a>, Dan, and Percy. <a href="https://arxiv.org/abs/2211.13972">[Paper]</a> </li>
<li><b>November 2022</b> We released HELM on the holistic evaluation of language models as CRFM's first flagship project with 50 coauthors, co-led with Percy and <a href="https://www.linkedin.com/in/tonyhlee">Tony Lee</a>. <a href="https://arxiv.org/abs/2211.09110">[Paper]</a> <a href="https://crfm.stanford.edu/helm">[Website]</a> <a href="https://crfm.stanford.edu/2022/11/17/helm.html">[Blog]</a></li> 
<li><b>September 2022</b> CRFM celebrated its 1 year anniversary, with <a href="https://venturebeat.com/author/sharongoldman/">Sharon Goldman</a> of VentureBeat writing on why 2022 is the year of foundation models. <a href="https://venturebeat.com/ai/foundation-models-2022s-ai-paradigm-shift/">[Press]</a> </li>
<li><b>August 2022</b> Our paper on the emergent abilities of language models, led by <a href="https://jasonwei20.github.io/">Jason Wei</a>, is published at TMLR. <a href="https://arxiv.org/abs/2206.07682">[arXiv]</a> <a href="https://venturebeat.com/2022/06/28/4-ai-research-trends-everyone-is-or-will-be-talking-about/">[Press]</a> </li>
<li><b>June 2022</b> HAI featured a story on my research journey and role in building the CRFM community. <a href="https://www.linkedin.com/pulse/rishi-bommasani-building-community-studying-foundation-models-?trk=public_post-content_share-article">[Story]</a> </li>
<li><b>May 2022</b> Percy, <a href="https://kathleenacreel.com/">Katie Creel</a>, <a href="http://robreich.stanford.edu/">Rob Reich</a>, and I argued for community norms to govern foundation models. <a href="https://crfm.stanford.edu/2022/05/17/community-norms.html">[Blog]</a> <a href="https://www.protocol.com/enterprise/foundation-models-ai-standards-stanford">[Press]</a> </li>
<li><b>August 2021</b> We inaugurated the <a href="https://crfm.stanford.edu/"> Center for Research on Foundation Models (CRFM)</a>, an amazing interdisciplinary initiative spanning 10+ departments! <a href="https://hai.stanford.edu/news/introducing-center-research-foundation-models-crfm">[Announcement Story]</a> </li>	  
<li><b>August 2021</b> We released our long report: <a href="https://arxiv.org/abs/2108.07258">On the Opportunties and Risks of Foundation Models</a>! Thanks to all 113 of my coauthors! <a href="https://crfm.stanford.edu/report.html">[Paper]</a> <a href="https://youtu.be/ZshcPdavsdU">[Explainer Video]</a> </li>	
</ul>
